{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Question 1\n"
      ],
      "metadata": {
        "id": "4jU2F_PxcgRB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
        "\n",
        "flyers = np.array([1, 2, 3, 1, 2]).reshape(-1, 1)\n",
        "cars_washed = np.array([12, 22, 29, 14, 24])\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(flyers, cars_washed)\n",
        "\n",
        "coef = model.coef_[0]\n",
        "intercept = model.intercept_\n",
        "\n",
        "baseline = np.mean(cars_washed)\n",
        "\n",
        "predictions = model.predict(flyers)\n",
        "shap_values = predictions - baseline\n",
        "\n",
        "verification = np.isclose(predictions, baseline + shap_values)\n",
        "\n",
        "comparison = [\"Over\" if p > a else \"Under\" if p < a else \"Exact\"\n",
        "              for p, a in zip(predictions, cars_washed)]\n",
        "\n",
        "df_results = pd.DataFrame({\n",
        "    \"Flyers (100s)\": flyers.flatten(),\n",
        "    \"Actual Cars\": cars_washed,\n",
        "    \"Predicted Cars\": predictions.round(2),\n",
        "    \"Baseline\": baseline,\n",
        "    \"SHAP Value\": shap_values.round(2),\n",
        "    \"Verification\": verification,\n",
        "    \"Prediction Type\": comparison\n",
        "})\n",
        "\n",
        "print(\"\\n Linear Regression Implementation with Coefficients \")\n",
        "print(f\"Coefficient: {coef:.2f}, Intercept: {intercept:.2f}\")\n",
        "\n",
        "print(\"\\n Baseline (Mean of y) \")\n",
        "print(f\"Baseline Value: {baseline:.2f}\")\n",
        "\n",
        "print(\"\\n Table of SHAP values and Predictions \")\n",
        "print(df_results)\n",
        "\n",
        "print(\"\\n Explanation of Input Influence \")\n",
        "for i, (x, shap, pred, actual) in enumerate(zip(flyers.flatten(), shap_values, predictions, cars_washed)):\n",
        "    influence = \"increased\" if shap > 0 else \"decreased\"\n",
        "    print(f\"Record {i+1}: Flyers={x} {influence} prediction by {abs(shap):.2f} cars. \"\n",
        "          f\"Predicted={pred:.2f}, Actual={actual}, Prediction Type={comparison[i]}\")\n",
        "\n",
        "print(\"\\n Model Accuracy \")\n",
        "r2 = r2_score(cars_washed, predictions)\n",
        "mae = mean_absolute_error(cars_washed, predictions)\n",
        "rmse = np.sqrt(mean_squared_error(cars_washed, predictions))\n",
        "print(f\"R² Score: {r2:.4f}\")\n",
        "print(f\"MAE: {mae:.2f}\")\n",
        "print(f\"RMSE: {rmse:.2f}\")\n",
        "\n",
        "print(\"\\n Trend Analysis \")\n",
        "if coef > 0:\n",
        "    print(\"As the number of flyers increases, the number of cars washed also increases.\")\n",
        "else:\n",
        "    print(\"Increasing flyers does not positively impact the number of cars washed.\")\n",
        "\n",
        "print(\"\\n SHAP Interpretation Insights \")\n",
        "print(\"SHAP values show how each flyer count influenced predictions compared to the baseline.\")\n",
        "print(\"Positive SHAP values indicate more flyers than average led to higher predicted washes,\")\n",
        "print(\"while negative values indicate fewer flyers led to lower predicted washes.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRhLHjYxcRgT",
        "outputId": "19d4b424-8420-41b1-dbe5-281f77aa75cd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Linear Regression Implementation with Coefficients \n",
            "Coefficient: 8.29, Intercept: 5.29\n",
            "\n",
            " Baseline (Mean of y) \n",
            "Baseline Value: 20.20\n",
            "\n",
            " Table of SHAP values and Predictions \n",
            "   Flyers (100s)  Actual Cars  Predicted Cars  Baseline  SHAP Value  \\\n",
            "0              1           12           13.57      20.2       -6.63   \n",
            "1              2           22           21.86      20.2        1.66   \n",
            "2              3           29           30.14      20.2        9.94   \n",
            "3              1           14           13.57      20.2       -6.63   \n",
            "4              2           24           21.86      20.2        1.66   \n",
            "\n",
            "   Verification Prediction Type  \n",
            "0          True            Over  \n",
            "1          True           Under  \n",
            "2          True            Over  \n",
            "3          True           Under  \n",
            "4          True           Under  \n",
            "\n",
            " Explanation of Input Influence \n",
            "Record 1: Flyers=1 decreased prediction by 6.63 cars. Predicted=13.57, Actual=12, Prediction Type=Over\n",
            "Record 2: Flyers=2 increased prediction by 1.66 cars. Predicted=21.86, Actual=22, Prediction Type=Under\n",
            "Record 3: Flyers=3 increased prediction by 9.94 cars. Predicted=30.14, Actual=29, Prediction Type=Over\n",
            "Record 4: Flyers=1 decreased prediction by 6.63 cars. Predicted=13.57, Actual=14, Prediction Type=Under\n",
            "Record 5: Flyers=2 increased prediction by 1.66 cars. Predicted=21.86, Actual=24, Prediction Type=Under\n",
            "\n",
            " Model Accuracy \n",
            "R² Score: 0.9573\n",
            "MAE: 1.09\n",
            "RMSE: 1.31\n",
            "\n",
            " Trend Analysis \n",
            "As the number of flyers increases, the number of cars washed also increases.\n",
            "\n",
            " SHAP Interpretation Insights \n",
            "SHAP values show how each flyer count influenced predictions compared to the baseline.\n",
            "Positive SHAP values indicate more flyers than average led to higher predicted washes,\n",
            "while negative values indicate fewer flyers led to lower predicted washes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 2"
      ],
      "metadata": {
        "id": "aPx8jC4Acnd8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# ===== Step 0: Create dataset =====\n",
        "data = pd.DataFrame({\n",
        "    'Chargers': [5, 3, 4, 2, 5],\n",
        "    'PeakHour': [1, 0, 1, 0, 0],\n",
        "    'Sessions': [80, 40, 70, 30, 60]\n",
        "})\n",
        "\n",
        "# Independent variables (X) and dependent variable (y)\n",
        "X = data[['Chargers', 'PeakHour']]\n",
        "y = data['Sessions']\n",
        "\n",
        "# ===== Step 1: Perform Multiple Linear Regression =====\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Regression coefficients and intercept\n",
        "coef_chargers, coef_peak = model.coef_\n",
        "intercept = model.intercept_\n",
        "\n",
        "print(\"Regression Equation: Sessions = {:.2f} + {:.2f}*(Chargers) + {:.2f}*(PeakHour)\"\n",
        "      .format(intercept, coef_chargers, coef_peak))\n",
        "\n",
        "# ===== Step 2: Calculate Baseline Value =====\n",
        "baseline = y.mean()\n",
        "print(\"Baseline Value (mean of Sessions):\", baseline)\n",
        "\n",
        "# ===== Step 3: Calculate SHAP Values =====\n",
        "# SHAP for linear regression: (feature_value - mean_feature_value) * coefficient\n",
        "mean_chargers = X['Chargers'].mean()\n",
        "mean_peak = X['PeakHour'].mean()\n",
        "\n",
        "shap_chargers = (X['Chargers'] - mean_chargers) * coef_chargers\n",
        "shap_peak = (X['PeakHour'] - mean_peak) * coef_peak\n",
        "\n",
        "# ===== Step 4: Compute Final Predictions =====\n",
        "predictions = baseline + shap_chargers + shap_peak\n",
        "\n",
        "# Verify decomposition\n",
        "verification = np.isclose(predictions, model.predict(X))\n",
        "\n",
        "# ===== Step 5: Combine Results =====\n",
        "results = pd.DataFrame({\n",
        "    'Chargers': X['Chargers'],\n",
        "    'PeakHour': X['PeakHour'],\n",
        "    'Actual Sessions': y,\n",
        "    'Predicted Sessions': model.predict(X).round(2),\n",
        "    'Baseline': baseline,\n",
        "    'SHAP Chargers': shap_chargers.round(2),\n",
        "    'SHAP PeakHour': shap_peak.round(2),\n",
        "    'Verified': verification\n",
        "})\n",
        "\n",
        "# Interpret over/underprediction\n",
        "results['Difference'] = results['Predicted Sessions'] - results['Actual Sessions']\n",
        "results['Interpretation'] = results['Difference'].apply(\n",
        "    lambda d: 'Overpredicted' if d > 0 else ('Underpredicted' if d < 0 else 'Exact')\n",
        ")\n",
        "\n",
        "print(\"\\nFinal Results:\")\n",
        "print(results)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kyUCp4rBwsNq",
        "outputId": "d754d83c-2c03-4dcf-d0a4-bad6bffd254f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Regression Equation: Sessions = 10.00 + 10.00*(Chargers) + 20.00*(PeakHour)\n",
            "Baseline Value (mean of Sessions): 56.0\n",
            "\n",
            "Final Results:\n",
            "   Chargers  PeakHour  Actual Sessions  Predicted Sessions  Baseline  \\\n",
            "0         5         1               80                80.0      56.0   \n",
            "1         3         0               40                40.0      56.0   \n",
            "2         4         1               70                70.0      56.0   \n",
            "3         2         0               30                30.0      56.0   \n",
            "4         5         0               60                60.0      56.0   \n",
            "\n",
            "   SHAP Chargers  SHAP PeakHour  Verified  Difference Interpretation  \n",
            "0           12.0           12.0      True         0.0          Exact  \n",
            "1           -8.0           -8.0      True         0.0          Exact  \n",
            "2            2.0           12.0      True         0.0          Exact  \n",
            "3          -18.0           -8.0      True         0.0          Exact  \n",
            "4           12.0           -8.0      True         0.0          Exact  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 3"
      ],
      "metadata": {
        "id": "rbb81ixIxc6P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 1. Load dataset\n",
        "diabetes = load_diabetes()\n",
        "X = pd.DataFrame(diabetes.data, columns=diabetes.feature_names)\n",
        "y = pd.Series(diabetes.target, name=\"disease_progression\")\n",
        "\n",
        "# 2. Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.25, random_state=42\n",
        ")\n",
        "\n",
        "# 3. Fit Multiple Linear Regression\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 4. Calculate baseline (mean of training targets)\n",
        "baseline = y_train.mean()\n",
        "\n",
        "# 5. Calculate SHAP-like contributions\n",
        "feature_means = X_train.mean()\n",
        "coefs = pd.Series(model.coef_, index=X.columns)\n",
        "\n",
        "# contributions = coef_j * (x_j - mean_j)\n",
        "contribs = (X_test - feature_means).multiply(coefs, axis=1)\n",
        "\n",
        "# 6. Predictions\n",
        "y_pred_model = pd.Series(model.predict(X_test), index=X_test.index)\n",
        "y_pred_decomp = baseline + contribs.sum(axis=1)\n",
        "\n",
        "# Verify decomposition\n",
        "max_abs_diff = np.abs(y_pred_model - y_pred_decomp).max()\n",
        "print(f\"Max absolute diff between model prediction and decomposition: {max_abs_diff}\")\n",
        "\n",
        "# 7. Build explanations\n",
        "explanations = []\n",
        "for idx in X_test.index:\n",
        "    contrib_dict = contribs.loc[idx].round(3).to_dict()\n",
        "    top_5 = sorted(contrib_dict.items(), key=lambda kv: abs(kv[1]), reverse=True)[:5]\n",
        "    explanations.append({\n",
        "        \"index\": idx,\n",
        "        \"actual\": y_test.loc[idx],\n",
        "        \"predicted\": y_pred_model.loc[idx],\n",
        "        \"baseline\": baseline,\n",
        "        \"error\": y_pred_model.loc[idx] - y_test.loc[idx],\n",
        "        \"contributions\": contrib_dict,\n",
        "        \"top_5_features\": top_5\n",
        "    })\n",
        "\n",
        "explanations_df = pd.DataFrame(explanations).set_index(\"index\")\n",
        "\n",
        "# Show first few explanations\n",
        "print(\"\\nFirst 5 explanations:\")\n",
        "print(explanations_df.head())\n",
        "\n",
        "# Example explanation for first test record\n",
        "first_idx = X_test.index[0]\n",
        "print(\"\\nExample explanation for test record:\", first_idx)\n",
        "print(\"Actual:\", y_test.loc[first_idx])\n",
        "print(\"Predicted:\", y_pred_model.loc[first_idx])\n",
        "print(\"Baseline:\", baseline)\n",
        "print(\"Sum of contributions:\", contribs.loc[first_idx].sum())\n",
        "print(\"Top 5 contributions:\", explanations_df.loc[first_idx, \"top_5_features\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8Z1mLaWwz03",
        "outputId": "7f6b1b86-23a8-4ebd-a5d4-ebefe8a74484"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max absolute diff between model prediction and decomposition: 4.263256414560601e-14\n",
            "\n",
            "First 5 explanations:\n",
            "       actual   predicted    baseline       error  \\\n",
            "index                                               \n",
            "287     219.0  137.949089  154.344411  -81.050911   \n",
            "211      70.0  182.533354  154.344411  112.533354   \n",
            "72      202.0  129.852954  154.344411  -72.147046   \n",
            "321     230.0  292.563092  154.344411   62.563092   \n",
            "73      111.0  124.867882  154.344411   13.867882   \n",
            "\n",
            "                                           contributions  \\\n",
            "index                                                      \n",
            "287    {'age': 2.117, 'sex': 10.871, 'bmi': -4.538, '...   \n",
            "211    {'age': 4.371, 'sex': 10.871, 'bmi': 18.396, '...   \n",
            "72     {'age': 2.984, 'sex': -12.196, 'bmi': -3.392, ...   \n",
            "321    {'age': 4.545, 'sex': 10.871, 'bmi': 26.423, '...   \n",
            "73     {'age': 0.555, 'sex': -12.196, 'bmi': -11.992,...   \n",
            "\n",
            "                                          top_5_features  \n",
            "index                                                     \n",
            "287    [(s1, -114.316), (s2, 63.609), (s5, 21.358), (...  \n",
            "211    [(s1, 23.44), (bmi, 18.396), (s5, -16.876), (s...  \n",
            "72     [(s1, -94.095), (s5, 57.581), (s2, 24.773), (s...  \n",
            "321    [(s5, 67.431), (s1, -49.862), (s4, 37.853), (b...  \n",
            "73     [(s1, -34.696), (s2, 27.002), (sex, -12.196), ...  \n",
            "\n",
            "Example explanation for test record: 287\n",
            "Actual: 219.0\n",
            "Predicted: 137.94908877812446\n",
            "Baseline: 154.34441087613294\n",
            "Sum of contributions: -16.39532209800846\n",
            "Top 5 contributions: [('s1', -114.316), ('s2', 63.609), ('s5', 21.358), ('sex', 10.871), ('s4', 9.014)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 4"
      ],
      "metadata": {
        "id": "w2ulc0yDxfSi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import shap\n",
        "\n",
        "# Student Performance dataset\n",
        "data = {\n",
        "    'study_time': [2, 4, 3, 2, 4, 5, 3, 2, 4, 3],\n",
        "    'parental_education': [4, 4, 3, 2, 4, 4, 3, 2, 4, 3],\n",
        "    'absences': [2, 1, 3, 4, 2, 1, 3, 4, 2, 1],\n",
        "    'failures': [0, 1, 0, 1, 0, 1, 0, 1, 0, 1],\n",
        "    'health': [4, 4, 3, 2, 4, 4, 3, 2, 4, 3],\n",
        "    'final_score': [70, 80, 60, 50, 85, 90, 65, 55, 80, 75]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Define features and target\n",
        "X = df[['study_time', 'parental_education', 'absences', 'failures', 'health']]\n",
        "y = df['final_score']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Perform Multiple Linear Regression Analysis\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Calculate the Baseline Value\n",
        "baseline = np.mean(y_train)\n",
        "\n",
        "# Calculate SHAP Values\n",
        "explainer = shap.LinearExplainer(model, X_train)\n",
        "shap_values = explainer.shap_values(X_test)\n",
        "\n",
        "# Compute Final Prediction for Each Record\n",
        "predictions = model.predict(X_test)\n",
        "for i in range(len(X_test)):\n",
        "    shap_contributions = shap_values[i]\n",
        "    prediction_from_shap = baseline + sum(shap_contributions)\n",
        "    print(f\"Record {i}:\")\n",
        "    print(f\"Predicted score from model: {predictions[i]}\")\n",
        "    print(f\"Predicted score from SHAP: {prediction_from_shap}\")\n",
        "    print(f\"Actual score: {y_test.iloc[i]}\")\n",
        "    print(f\"Baseline value: {baseline}\")\n",
        "    print(\"Feature contributions:\")\n",
        "    for feature, contribution in zip(X_test.columns, shap_contributions):\n",
        "        print(f\"{feature}: {contribution} ({'+' if contribution > 0 else ''}{contribution:.2f})\")\n",
        "    print(f\"Model {'overpredicted' if predictions[i] > y_test.iloc[i] else 'underpredicted'}\\n\")\n",
        "\n",
        "# Interpret the Results\n",
        "for i in range(len(X_test)):\n",
        "    print(f\"Record {i} Interpretation:\")\n",
        "    print(f\"Actual final score: {y_test.iloc[i]}\")\n",
        "    print(f\"Predicted final score: {predictions[i]}\")\n",
        "    difference = predictions[i] - y_test.iloc[i]\n",
        "    if difference > 0:\n",
        "        print(f\"The model overpredicted by {difference:.2f}\")\n",
        "    elif difference < 0:\n",
        "        print(f\"The model underpredicted by {abs(difference):.2f}\")\n",
        "    else:\n",
        "        print(\"The model predicted perfectly\")\n",
        "    print(\"SHAP values for each feature:\")\n",
        "    for feature, value in zip(X_test.columns, shap_values[i]):\n",
        "        if value > 0:\n",
        "            print(f\"{feature}: +{value:.2f} (increased the prediction)\")\n",
        "        else:\n",
        "            print(f\"{feature}: {value:.2f} (decreased the prediction)\")\n",
        "    print(\"\\n\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_R1QMW6xFNF",
        "outputId": "be6b57ce-6be5-430b-a83b-92e64bdade34"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Record 0:\n",
            "Predicted score from model: 80.55555555555556\n",
            "Predicted score from SHAP: 80.55555555555556\n",
            "Actual score: 80\n",
            "Baseline value: 68.75\n",
            "Feature contributions:\n",
            "study_time: 4.722222222222222 (+4.72)\n",
            "parental_education: 3.888888888888883 (+3.89)\n",
            "absences: 1.3888888888888884 (+1.39)\n",
            "failures: -2.083333333333334 (-2.08)\n",
            "health: 3.888888888888897 (+3.89)\n",
            "Model overpredicted\n",
            "\n",
            "Record 1:\n",
            "Predicted score from model: 87.5\n",
            "Predicted score from SHAP: 87.5\n",
            "Actual score: 80\n",
            "Baseline value: 68.75\n",
            "Feature contributions:\n",
            "study_time: 4.722222222222222 (+4.72)\n",
            "parental_education: 3.888888888888883 (+3.89)\n",
            "absences: 4.166666666666665 (+4.17)\n",
            "failures: 2.083333333333334 (+2.08)\n",
            "health: 3.888888888888897 (+3.89)\n",
            "Model overpredicted\n",
            "\n",
            "Record 0 Interpretation:\n",
            "Actual final score: 80\n",
            "Predicted final score: 80.55555555555556\n",
            "The model overpredicted by 0.56\n",
            "SHAP values for each feature:\n",
            "study_time: +4.72 (increased the prediction)\n",
            "parental_education: +3.89 (increased the prediction)\n",
            "absences: +1.39 (increased the prediction)\n",
            "failures: -2.08 (decreased the prediction)\n",
            "health: +3.89 (increased the prediction)\n",
            "\n",
            "\n",
            "Record 1 Interpretation:\n",
            "Actual final score: 80\n",
            "Predicted final score: 87.5\n",
            "The model overpredicted by 7.50\n",
            "SHAP values for each feature:\n",
            "study_time: +4.72 (increased the prediction)\n",
            "parental_education: +3.89 (increased the prediction)\n",
            "absences: +4.17 (increased the prediction)\n",
            "failures: +2.08 (increased the prediction)\n",
            "health: +3.89 (increased the prediction)\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}